{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8389f657-6ce3-477e-82ea-8baa0062e8c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta table refreshed with the latest data.\nDelta table refreshed with the latest data.\nDelta table refreshed with the latest data.\nDelta table refreshed with the latest data.\nDelta table refreshed with the latest data.\nDelta table refreshed with the latest data.\nDelta table refreshed with the latest data.\nDelta table refreshed with the latest data.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SalesDataRefresh\").getOrCreate()\n",
    "\n",
    "json_file_path = \"dbfs:/FileStore/sales_data/sample_sales.json\"\n",
    "delta_table_path = \"file:/tmp/delta_table\"\n",
    "\n",
    "while True:\n",
    "    df = spark.read.json(json_file_path)\n",
    "    \n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "    \n",
    "    print(\"Delta table refreshed with the latest data.\")\n",
    "    \n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook_B_Scheduled_Job_Simulation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
